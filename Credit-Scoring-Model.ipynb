{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "436fe591-a720-43b2-87f9-46474482ed95",
   "metadata": {},
   "source": [
    "## Step 1: Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb410cd8-a2e0-4d6f-b57d-1884ebef4984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows of the loan dataset:\n",
      "    Loan_ID Gender Married Dependents     Education Self_Employed  \\\n",
      "0  LP001002   Male      No          0      Graduate            No   \n",
      "1  LP001003   Male     Yes          1      Graduate            No   \n",
      "2  LP001005   Male     Yes          0      Graduate           Yes   \n",
      "3  LP001006   Male     Yes          0  Not Graduate            No   \n",
      "4  LP001008   Male      No          0      Graduate            No   \n",
      "\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0         NaN             360.0   \n",
      "1             4583             1508.0       128.0             360.0   \n",
      "2             3000                0.0        66.0             360.0   \n",
      "3             2583             2358.0       120.0             360.0   \n",
      "4             6000                0.0       141.0             360.0   \n",
      "\n",
      "   Credit_History Property_Area Loan_Status  \n",
      "0             1.0         Urban           Y  \n",
      "1             1.0         Rural           N  \n",
      "2             1.0         Urban           Y  \n",
      "3             1.0         Urban           Y  \n",
      "4             1.0         Urban           Y  \n",
      "\n",
      "==================================================\n",
      "\n",
      "Loan DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   Loan_ID            614 non-null    object \n",
      " 1   Gender             601 non-null    object \n",
      " 2   Married            611 non-null    object \n",
      " 3   Dependents         599 non-null    object \n",
      " 4   Education          614 non-null    object \n",
      " 5   Self_Employed      582 non-null    object \n",
      " 6   ApplicantIncome    614 non-null    int64  \n",
      " 7   CoapplicantIncome  614 non-null    float64\n",
      " 8   LoanAmount         592 non-null    float64\n",
      " 9   Loan_Amount_Term   600 non-null    float64\n",
      " 10  Credit_History     564 non-null    float64\n",
      " 11  Property_Area      614 non-null    object \n",
      " 12  Loan_Status        614 non-null    object \n",
      "dtypes: float64(4), int64(1), object(8)\n",
      "memory usage: 62.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Import the pandas library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Define the full path to your training CSV file\n",
    "# Note: I'm using the exact filename from your screenshot. You can rename it to 'train.csv' to make it simpler.\n",
    "file_path = r'C:\\Users\\user 1\\Documents\\Apollos\\credit-scoring-model\\train_u6lujux_CVtuZ9i.csv'\n",
    "\n",
    "# Load the CSV file into a pandas DataFrame\n",
    "df_loan = pd.read_csv(file_path)\n",
    "\n",
    "# --- Initial Inspection ---\n",
    "\n",
    "# 1. Display the first 5 rows to understand the features\n",
    "print(\"First 5 rows of the loan dataset:\")\n",
    "print(df_loan.head())\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Get a concise summary of the DataFrame to check for missing values and data types\n",
    "print(\"Loan DataFrame Information:\")\n",
    "df_loan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b9dc19-f3b0-4b3f-b225-be5c087b8517",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8dbd19b-ffce-42d2-a41d-795a6bf842b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types after processing:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 614 entries, 0 to 613\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   ApplicantIncome          614 non-null    int64  \n",
      " 1   CoapplicantIncome        614 non-null    float64\n",
      " 2   LoanAmount               614 non-null    float64\n",
      " 3   Loan_Amount_Term         614 non-null    float64\n",
      " 4   Credit_History           614 non-null    float64\n",
      " 5   Loan_Status              614 non-null    int64  \n",
      " 6   Gender_Male              614 non-null    bool   \n",
      " 7   Married_Yes              614 non-null    bool   \n",
      " 8   Dependents_1             614 non-null    bool   \n",
      " 9   Dependents_2             614 non-null    bool   \n",
      " 10  Dependents_3+            614 non-null    bool   \n",
      " 11  Education_Not Graduate   614 non-null    bool   \n",
      " 12  Self_Employed_Yes        614 non-null    bool   \n",
      " 13  Property_Area_Semiurban  614 non-null    bool   \n",
      " 14  Property_Area_Urban      614 non-null    bool   \n",
      "dtypes: bool(9), float64(4), int64(2)\n",
      "memory usage: 34.3 KB\n",
      "None\n",
      "\n",
      "==================================================\n",
      "\n",
      "First 5 rows of the processed dataset:\n",
      "   ApplicantIncome  CoapplicantIncome  LoanAmount  Loan_Amount_Term  \\\n",
      "0             5849                0.0  146.412162             360.0   \n",
      "1             4583             1508.0  128.000000             360.0   \n",
      "2             3000                0.0   66.000000             360.0   \n",
      "3             2583             2358.0  120.000000             360.0   \n",
      "4             6000                0.0  141.000000             360.0   \n",
      "\n",
      "   Credit_History  Loan_Status  Gender_Male  Married_Yes  Dependents_1  \\\n",
      "0             1.0            1         True        False         False   \n",
      "1             1.0            0         True         True          True   \n",
      "2             1.0            1         True         True         False   \n",
      "3             1.0            1         True         True         False   \n",
      "4             1.0            1         True        False         False   \n",
      "\n",
      "   Dependents_2  Dependents_3+  Education_Not Graduate  Self_Employed_Yes  \\\n",
      "0         False          False                   False              False   \n",
      "1         False          False                   False              False   \n",
      "2         False          False                   False               True   \n",
      "3         False          False                    True              False   \n",
      "4         False          False                   False              False   \n",
      "\n",
      "   Property_Area_Semiurban  Property_Area_Urban  \n",
      "0                    False                 True  \n",
      "1                    False                False  \n",
      "2                    False                 True  \n",
      "3                    False                 True  \n",
      "4                    False                 True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\AppData\\Local\\Temp\\ipykernel_8036\\842629777.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
      "C:\\Users\\user 1\\AppData\\Local\\Temp\\ipykernel_8036\\842629777.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_processed[col].fillna(df_processed[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Data Preprocessing ---\n",
    "\n",
    "# Make a copy to keep the original data safe\n",
    "df_processed = df_loan.copy()\n",
    "\n",
    "# 1. Drop the Loan_ID column as it is not needed for prediction\n",
    "df_processed = df_processed.drop('Loan_ID', axis=1)\n",
    "\n",
    "# 2. Fill missing values (Imputation)\n",
    "# For categorical columns, we'll fill missing values with the most frequent value (the 'mode')\n",
    "for col in ['Gender', 'Married', 'Dependents', 'Self_Employed']:\n",
    "    df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)\n",
    "\n",
    "# For numerical columns, we'll fill missing values with the average value (the 'mean')\n",
    "for col in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    df_processed[col].fillna(df_processed[col].mean(), inplace=True)\n",
    "\n",
    "# 3. Convert categorical columns to numbers\n",
    "# Machine learning models only understand numbers. We will convert text categories into numerical representations.\n",
    "# We will use one-hot encoding for most columns, and a simple map for our target variable.\n",
    "df_processed['Loan_Status'] = df_processed['Loan_Status'].map({'Y': 1, 'N': 0})\n",
    "\n",
    "# Use get_dummies for one-hot encoding of other categorical features\n",
    "df_processed = pd.get_dummies(df_processed, drop_first=True)\n",
    "\n",
    "\n",
    "# --- Verification ---\n",
    "print(\"Data types after processing:\")\n",
    "print(df_processed.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"First 5 rows of the processed dataset:\")\n",
    "print(df_processed.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e6568-1f71-401a-807c-84c810877a91",
   "metadata": {},
   "source": [
    "## Step 3: Building and Training the Model\n",
    "This is the core of the project. We will now split our data, train a machine learning model, and then test its performance.\n",
    "\n",
    "**1. Define Features (X) and Target (y):** We separate our dataset into two parts: the features (all the columns we use to make a prediction) and the target (the actual outcome we want to predict, Loan_Status).\n",
    "\n",
    "**2. Split the Data:** We can't test our model on the same data it learned from; that would be like giving a student the answers before an exam. We split our data into a \"training set\" (for the model to learn from) and a \"testing set\" (to evaluate its performance on unseen data).\n",
    "\n",
    "**3. Train the Model:** We will \"fit\" a LogisticRegression model to the training data. This is the process where the model learns the relationships between the features and the loan status.\n",
    "\n",
    "**4. Make Predictions:** We use our trained model to make predictions on the unseen test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc63c0f1-2987-4209-bf99-d8b9605fbffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.79\n",
      "\n",
      "==================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18 25]\n",
      " [ 1 79]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.42      0.58        43\n",
      "           1       0.76      0.99      0.86        80\n",
      "\n",
      "    accuracy                           0.79       123\n",
      "   macro avg       0.85      0.70      0.72       123\n",
      "weighted avg       0.83      0.79      0.76       123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries from scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- Model Building ---\n",
    "\n",
    "# 1. Define our features (X) and target (y)\n",
    "# X contains all columns except 'Loan_Status'\n",
    "X = df_processed.drop('Loan_Status', axis=1)\n",
    "# y contains only the 'Loan_Status' column\n",
    "y = df_processed['Loan_Status']\n",
    "\n",
    "# 2. Split the data into training and testing sets\n",
    "# We'll use 80% of the data for training and 20% for testing\n",
    "# random_state ensures we get the same split every time we run the code\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000) # max_iter helps the model converge\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# --- Model Evaluation ---\n",
    "\n",
    "# 5. Check the model's accuracy and other metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "# A confusion matrix shows us True Positives, True Negatives, False Positives, and False Negatives\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "# This report gives us precision, recall, and f1-score, which are key performance indicators\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b2a37f-1305-4646-acd5-548fe06433cb",
   "metadata": {},
   "source": [
    "## Interpreting The Model's Performance\n",
    "**1. Overall Accuracy: 79%**\n",
    "The model correctly predicted the loan status for 79% of the applicants in the test set. This is a good starting point, but accuracy alone can be misleading, especially when one class is more common than the other.\n",
    "\n",
    "**2. The Confusion Matrix**\n",
    "This little table is the most honest report card for our model.\n",
    "```\n",
    "[[18 25]\n",
    "[ 1 79]]\n",
    "```\n",
    "\n",
    "- **18 (True Negatives):** The model correctly predicted 18 people would default, and they did.\n",
    "\n",
    "- **79 (True Positives):** The model correctly predicted 79 people would repay, and they did.\n",
    "\n",
    "- **1 (False Negatives):** The model incorrectly predicted 1 person would repay, but they actually defaulted. This is the most costly mistake for the business.\n",
    "\n",
    "- **25 (False Positives):** The model incorrectly predicted 25 people would default, but they would have actually repaid. This is a missed business opportunity.\n",
    "\n",
    "**3. The Classification Report (The Deep Dive)**\n",
    "This is where we see the real story. Let's focus on predicting defaults (class `0`).\n",
    "\n",
    "- **Precision (0.95 for class 0):** When the model predicts someone will default, it is correct 95% of the time. This is very good. It means the model is very reliable when it raises a red flag.\n",
    "\n",
    "- **Recall (0.42 for class 0):** This is our model's weakness. It only successfully identified 42% of all the people who actually defaulted. It missed the other 58%.\n",
    "\n",
    "**The Business Story:** This model is cautious and accurate when it predicts a default, but it's not very good at finding all the defaulters. From a business perspective, I may want to improve the recall, even if it means lowering precision slightly, to catch more potential losses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1881762-dcb8-474f-9a90-e4fa828e3ed7",
   "metadata": {},
   "source": [
    "## Final Step: Predicting on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4180539-a534-4829-bedc-059efe6571ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the test file:\n",
      "    Loan_ID Predicted_Loan_Status\n",
      "0  LP001015                     Y\n",
      "1  LP001022                     Y\n",
      "2  LP001031                     Y\n",
      "3  LP001035                     Y\n",
      "4  LP001051                     Y\n",
      "5  LP001054                     Y\n",
      "6  LP001055                     Y\n",
      "7  LP001056                     N\n",
      "8  LP001059                     Y\n",
      "9  LP001067                     Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user 1\\AppData\\Local\\Temp\\ipykernel_8036\\187090093.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_cleaned[col].fillna(df_test_cleaned[col].mode()[0], inplace=True)\n",
      "C:\\Users\\user 1\\AppData\\Local\\Temp\\ipykernel_8036\\187090093.py:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_test_cleaned[col].fillna(df_test_cleaned[col].mean(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# --- Predicting on the Test File ---\n",
    "\n",
    "# 1. Load the test dataset\n",
    "test_file_path = r'C:\\Users\\user 1\\Documents\\Apollos\\credit-scoring-model\\test_Y3wMUE5_7gLdATN.csv'\n",
    "df_test = pd.read_csv(test_file_path)\n",
    "\n",
    "# Keep the Loan_ID for our final submission file\n",
    "test_loan_ids = df_test['Loan_ID']\n",
    "\n",
    "# 2. Preprocess the test data\n",
    "# Drop Loan_ID first\n",
    "df_test_cleaned = df_test.drop('Loan_ID', axis=1)\n",
    "\n",
    "# Fill missing categorical values with the mode\n",
    "for col in ['Gender', 'Married', 'Dependents', 'Self_Employed']:\n",
    "    # Check if column exists before filling\n",
    "    if col in df_test_cleaned.columns:\n",
    "        df_test_cleaned[col].fillna(df_test_cleaned[col].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing numerical values with the mean\n",
    "for col in ['LoanAmount', 'Loan_Amount_Term', 'Credit_History']:\n",
    "    if col in df_test_cleaned.columns:\n",
    "        df_test_cleaned[col].fillna(df_test_cleaned[col].mean(), inplace=True)\n",
    "\n",
    "# Convert categorical columns to numbers\n",
    "df_test_processed = pd.get_dummies(df_test_cleaned, drop_first=True)\n",
    "\n",
    "# 3. Align columns with the training data\n",
    "df_test_processed = df_test_processed.reindex(columns=X.columns, fill_value=0)\n",
    "\n",
    "# 4. Make predictions\n",
    "final_predictions = model.predict(df_test_processed)\n",
    "\n",
    "# 5. Create and display the final submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'Loan_ID': test_loan_ids,\n",
    "    'Predicted_Loan_Status': final_predictions\n",
    "})\n",
    "submission_df['Predicted_Loan_Status'] = submission_df['Predicted_Loan_Status'].map({1: 'Y', 0: 'N'})\n",
    "\n",
    "print(\"Predictions for the test file:\")\n",
    "print(submission_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5a64e5-04be-4889-b443-f728a0f9f5e1",
   "metadata": {},
   "source": [
    "## Project Summary\n",
    "This project addresses a critical business problem in the fintech sector: credit risk assessment. The goal was to build a machine learning model to predict loan default probability for a microfinance institution. Using a loan prediction dataset from Kaggle, the project involved a complete data science workflow, including data cleaning, imputation of missing values, and feature engineering to prepare the data for modeling. A **Logistic Regression** model was trained and evaluated, achieving an overall **accuracy of 79%.** More importantly, the model demonstrated a **precision of 95%** in predicting defaults, indicating high reliability when flagging high-risk applicants, though its recall of 42% suggests opportunities for future improvement in identifying all potential defaulters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
